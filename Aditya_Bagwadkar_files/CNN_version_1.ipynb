{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional neural network from scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fnAdsTgMRfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIIbgsNOMY58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zero_pad(X,pad):\n",
        "  X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),'constant',constant_values=(0,0))\n",
        "  return X_pad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNDYiWlpk8HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnPFg7rZlv-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_single_step(a_slice_prev,W,b):\n",
        "  s=a_slice_prev\n",
        "  Z=np.sum(s)\n",
        "  \n",
        "  Z1=float(Z+b)\n",
        "  return Z1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFTLcUmYnSJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_forward(A_prev,W,b,hyper_parameters):\n",
        "  (m,n_H_prev,n_W_prev,n_C_prev)=np.shape(A_prev)\n",
        "  fig,axarr=plt.subplots(1,2)\n",
        "  print(\"\\nNumber of training examples = \",m)\n",
        "  print(\"\\nHeight dimension of output of previous layer =\",n_H_prev)\n",
        "  print(\"\\nWidth  dimension of output of previous layer =\",n_W_prev)\n",
        "  print(\"\\nNumber of channels in the  output of previous layer =\",n_C_prev)\n",
        "\n",
        "  (f,f,n_C_prev,n_C)=np.shape(W)\n",
        "\n",
        "  print(\"\\nHeight dimension of filter kernel =\",f)\n",
        "  print(\"\\nWidth  dimension of filter kernel =\",f)\n",
        "  print(\"\\nTotal number of filters or number of channels after applying convolutional layer =\",n_C)\n",
        "\n",
        "  stride=hyper_parameters['stride']\n",
        "  pad=hyper_parameters['pad']\n",
        "\n",
        "  print(\"\\nNumber of steps used by filter to move or parse across the output of previous layer =\",stride)\n",
        "  print(\"\\nAmount of padding around each image on vertical and horizontal dimensions = \",pad)\n",
        "\n",
        "  print(\"\\nComputing the height and width dimension of the output using formulas:-\\n\\n\") \n",
        "  print(\"\\n       | n_H_prev - f + 2*pad |                | n_W_prev - f + 2*pad |\")    \n",
        "  print(\"\\n n_H = |----------------------| + 1     n_W =  |----------------------| + 1\")\n",
        "  print(\"\\n       |       stride         |                |       stride         |\")\n",
        "\n",
        "  n_H = int((n_H_prev-f+2*pad)/stride)+1\n",
        "  n_W = int((n_W_prev-f+2*pad)/stride)+1\n",
        "\n",
        "  print(\"\\nHeight dimension of the result = \",n_H) \n",
        "  print(\"\\nWidth  dimension of the result = \",n_W) \n",
        "\n",
        "  Z = np.zeros((m,n_H,n_W,n_C))\n",
        "  print(\"\\nDimensions of the result = \",Z.shape)\n",
        "  \n",
        "\n",
        "  print(\"\\nPadding the input data by zeros \\n\")\n",
        "  A_prev_pad=zero_pad(A_prev,pad)\n",
        "  print(\"\\nDimensions after padding = \",A_prev_pad.shape)\n",
        "  \n",
        "\n",
        "  print(\"\\n Applying convolutional filters on the input data .........\")\n",
        "  for i in range(m):\n",
        "    a_prev_pad = A_prev_pad[i,:,:,:]\n",
        "    \n",
        "    for h in range(n_H):\n",
        "      vert_start = h*stride\n",
        "      vert_end   = h*stride + f\n",
        "\n",
        "      for w in range(n_W):\n",
        "        horiz_start = w*stride\n",
        "        horiz_end   = w*stride + f\n",
        "\n",
        "        for c in range(n_C):\n",
        "          a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
        "\n",
        "          weights = W[:,:,:,c]\n",
        "          biases  = b[:,:,:,c]\n",
        "\n",
        "          Z[i,h,w,c] = conv_single_step(a_slice_prev,weights,biases)\n",
        "          axarr[0].imshow(A_prev[i,:,:,0])\n",
        "          axarr[1].imshow(A_prev_pad[i,:,:,0])\n",
        "          \n",
        "          \n",
        "  assert(Z.shape == (m,n_H,n_W,n_C))\n",
        "\n",
        "  cache = (A_prev,W,b,hyper_parameters)\n",
        "\n",
        "  return Z,cache\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUm91-GGzmHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36762a01-833c-478d-f393-ec9cca4b8b70"
      },
      "source": [
        "np.random.seed(1)\n",
        "A_prev=np.random.randn(10,5,7,4)\n",
        "W = np.random.randn(3,3,4,8)\n",
        "b=np.random.randn(1,1,1,8)\n",
        "hyper_parameters= {\"pad\":1,\"stride\":2}\n",
        "\n",
        "Z,cache_conv=conv_forward(A_prev,W,b,hyper_parameters)\n",
        "\n",
        "print(\"\\nZ's mean = \\n\",np.mean(Z))\n",
        "print(\"\\nZ[3,2,1]= \\n\",Z[3,2,1])\n",
        "print(\"\\ncache_conv[0][1][2][3] = \\n \",cache_conv[0][1][2][3])"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of training examples =  10\n",
            "\n",
            "Height dimension of output of previous layer = 5\n",
            "\n",
            "Width  dimension of output of previous layer = 7\n",
            "\n",
            "Number of channels in the  output of previous layer = 4\n",
            "\n",
            "Height dimension of filter kernel = 3\n",
            "\n",
            "Width  dimension of filter kernel = 3\n",
            "\n",
            "Total number of filters or number of channels after applying convolutional layer = 8\n",
            "\n",
            "Number of steps used by filter to move or parse across the output of previous layer = 2\n",
            "\n",
            "Amount of padding around each image on vertical and horizontal dimensions =  1\n",
            "\n",
            "Computing the height and width dimension of the output using formulas:-\n",
            "\n",
            "\n",
            "\n",
            "       | n_H_prev - f + 2*pad |                | n_W_prev - f + 2*pad |\n",
            "\n",
            " n_H = |----------------------| + 1     n_W =  |----------------------| + 1\n",
            "\n",
            "       |       stride         |                |       stride         |\n",
            "\n",
            "Height dimension of the result =  3\n",
            "\n",
            "Width  dimension of the result =  4\n",
            "\n",
            "Dimensions of the result =  (10, 3, 4, 8)\n",
            "\n",
            "Padding the input data by zeros \n",
            "\n",
            "\n",
            "Dimensions after padding =  (10, 7, 9, 4)\n",
            "\n",
            " Applying convolutional filters on the input data .........\n",
            "\n",
            "Z's mean = \n",
            " 1.9498833149593615\n",
            "\n",
            "Z[3,2,1]= \n",
            " [-2.14101107 -4.47067799 -2.45996536 -4.88183244 -1.78091765 -4.77884206\n",
            " -4.41652613 -3.6562308 ]\n",
            "\n",
            "cache_conv[0][1][2][3] = \n",
            "  [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAACVCAYAAABxa7CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAMMUlEQVR4nO3da4zcVR3G8edx2lIoLa1aL7BAEY2m0ZRiRbSRKJdYLlETiQEjUaMSjUpREqW+0hdeXhiEKME0XDQBbSoQRdOIGCCEaMql1CotFUSUItISCq2F0m79+WJn67Cd3fnvzvnPObPz/SSb7OXPbx/a9Jcz55w5xxEhAEC5XpU7AABgYjRqACgcjRoACkejBoDC0agBoHAzcgcA+kVj3pyYuXB+7hiYpvbveF4Hdu1xu5/RqIGKZi6cr6Hvfj53DExT21b9eNyfMfUBAIWjUQNA4WjUAFC4Wuao61p0mdk4kLymJO0/0EheM4bbrgl07R3zn62l7qN7j6ql7v6ds5LX3Lf7OQ2/1H7RBZiOamnUMxfO19B3vpC87tGveSF5TUl65oW5yWvu3XF48pqSdN9HVtdS95yt59RS95k1xyevufWWHySrZXuFpKskNSRdGxHfS1YcSISpDwws2w1JV0s6W9JiSRfaXpw3FXAoGjUG2SmSHouIxyNin6Q1kj6cORNwCBo1Btkxkp5s+Xpb83sH2b7Y9gO2Hziwa09PwwGjaNTABCJidUQsi4hljXlzcsfBgKJRY5A9JenYlq+Hmt8DikKjxiC7X9JbbJ9ge5akCyTdljkTcIhKjdr2CttbbT9m+/K6QwG9EBHDkr4k6XZJWyStjYiH86YCDtVxH3XLFqazNLLYcr/t2yJic93hgLpFxDpJ63LnACZSZUTNFiYAyKhKo+64hUliGxMA1CXZW8gjYrWk1ZI0+8RjIlVdYFqJ7o8oSXGUQopjE1Ick/D3BEcipDj+IMVRB7s/UN8AtcqImi1MAJBRlUbNFiYAyKjj1EdEDNse3cLUkHQ9W5gAoHcqzVGzhQkA8uGdiQBQOBo1ABSORg0AhaNRA0DhaNQAULhaLrede9henfnmrcnr3nPLyclrStKpH/lz8ppnL9mUvKYkfe7J5bXUfeGa42qpe+Ilf01e84m79iavCZSMETUAFI5GDQCFo1EDQOFo1ABQOBo1ABSORg0Ahatlex6A9lJsW02xTTXFltQUW1BTbDdNsbU0xTbSjdsOufgqmY4jatvX295u+y+1pQAAjKvK1MdPJK2oOQcAYBwdG3VE3CPpuR5kAQC0kWwxsfUW8r07X05VFgAGXrJGHRGrI2JZRCybveCwVGWB2tg+1vZdtjfbftj2ytyZgHbY9YFBNizpsojYYHuupAdt3xERm3MHA1qxjxoDKyKejogNzc93S9oiqb49VsAUVdme93NJf5T0VtvbbH+m/lhAb9leJGmppPV5kwCH6jj1EREX9iIIkIvtIyXdIunSiNg15mcXS7pYkma89qgM6QCmPjDgbM/USJO+KSJuHfvz1kXyxrw5vQ8IiEaNAWbbkq6TtCUirsidBxgPjRqDbLmkiySdbntj8+Oc3KGAsdieh4EVEfdKcu4cQCeMqAGgcLWMqGf6gF4/a1fnByfptI9uSF5Tki573e+T1/z0IxclrylJnzzuj7XUffWqPbXU/dWj70he86X9s5LXBErGiBoACsccNdBDKV5ppnhlmeJVZIpXjSleIaZ4NVjHK7+UGFEDQOFo1ABQOBo1ABSORg0Ahatyeh6HqwNARlV2fXC4OgBkVOVyWw5XB4CMJjVHzeHqANB7lRv1RIerN39+8BbyF3fuS5kRAAZapUbd6XB16ZUHrB+xgLMYACCVKrs+OFwdADKqMqLmcHUAyKjK5bYcrg4AGfHORAAoHI0aAApHowaAwnFxANBDv/jZ+7uusW/pf7qu8bd37e26xouffUPXNX590ZKua2zatKjrGh9/3x+6rrH2kaVd1xgPI2oAKFwtI+qdz81NMnIYK8VIop0Uo4uxUow22kkxAmknxaiknRQjlbFumP1i8ppAyRhRA0DhaNQAUDgaNQaa7Ybth2z/JncWYDw0agy6lRo5Yx0oFo0aA8v2kKRzJV2bOwswERo1BtmVkr4m6b+5gwAToVFjINk+T9L2iHiww3MHL8Q4sGtPj9IBr1TlPOrZtu+z/afmLeTf6kUwoGbLJX3I9hOS1mjkGN8bxz7UeiFGY96cXmcEJFUbUb8s6fSIWCLpJEkrbJ9abyygXhGxKiKGImKRpAsk3RkRn8gcC2irynnUIWn0LYEzmx9RZygAwP9VvTOxYXujpO2S7oiIQ24hb53LG36RuTz0j4i4OyLOy50DGE+lRh0RByLiJElDkk6x/fY2zxycy5txBHN5AJDKpHZ9RMTzku6StKKeOACAsars+lhoe37z88MlnSXpkbqDAQBGVDnm9I2Sfmq7oZHGvjYiOBcBmIIzP3Zf1zWOO+y5rmv88vbuj8vd/UDXJbT5D2/qusaMBFdvn39U9/8za1XfxQFVdn1skmpMAACYEO9MBIDC0agBoHA0agAoHI0aAApHowaAwtVyC/m8BXuSbEMaK8W2pHZSbFUaK8XWpXZSbGdqJ8UWp3ZSbHsa65cNjijAYGFEDQCFo1EDQOFo1ABQOBo1ABSORg0AhaNRA0DhaNQAULjKjbp5HddDtjniFAB6aDIj6pWSttQVBADQXqV3JtoeknSupG9L+mqtiYBpbN2ji3NHSOfE6fMO0Y+t/1zuCBOqOqK+UtLXJP13vAdabyF/aefLScIBAKrdmXiepO0R8eBEz7XeQn74gsOSBQSAQVdlRL1c0odsPyFpjaTTbd9YayoAwEEdG3VErIqIoYhYJOkCSXdGxCdqTwYAkMQ+agw42/Nt32z7EdtbbL8ndyZgrEmdRx0Rd0u6u5YkQB5XSfptRJxve5akI3IHAsaq5eIAoB/YPkrSaZI+JUkRsU/SvpyZgHaY+sAgO0HSDkk3NN91e63tOa0PtG47PbBr+uwbRn+hUWOQzZB0sqRrImKppD2SLm99oHXbaWPenHY1gNrRqDHItknaFhHrm1/frJHGDRSFRo2BFRH/lvSk7bc2v3WGpM0ZIwFt1bKYuH3Lzmd/ePKaf1R49LWSnq0jw+T8ruqDheStpIis7/x65Ucnk/f4KYVp78uSbmru+Hhc0qcT1gaSqKVRR8TCKs/ZfiAiltWRoQ79lLefskr58kbERkl98+eEwcTUBwAUjkYNAIXL3ahXZ/79k9VPefspq9R/eYGecUTkzgD0Bds7JHVaJC9hEbeEDBI5xuqU4/jx1vdo1EBCJSzilpCBHGlz5J76AAB0kK1R215he6vtx2xf3vm/yMP2sbbvsr3Z9sO2V+bOVEW/3BrPMaNAZ1kate2GpKslnS1psaQLbZd66+ewpMsiYrGkUyV9seCsrfrl1vjRY0bfJmmJ+iPzREpYFC0hg0SOsaacI8scdXPU9M2I+GDz61WSFBHf7XmYSbL9K0k/iog7cmcZT/PW+J+qeWt8RJyXOVJbzWNGN0p6U7BYAowr19THMZKebPl6W/N7RbO9SNJSSesnfjK7jrfGF6LjMaMAWEyszPaRkm6RdGlE7MqdZzxVb40vRMdjRgHka9RPSTq25euh5veKZHumRpr0TRFxa+48HfTTrfHT5pjREhbHS1v4LmFBu4TFattfaf59/MX2z23PnmyNXI36fklvsX1C89SyCyTdlinLhGxb0nWStkTEFbnzdNJPt8ZPl2NGC1ocL23hu4QF7ayL1baPkXSJpGUR8XZJDY38u5yULI06IoYlfUnS7Rr5g1sbEQ/nyFLBckkXaWRkurH5cU7uUNPI6DGjmySdJOk7mfNMxSmSHouIx5v3Lq6R9OFeh4iIpyNiQ/Pz3Rr5t5Vl7ae5oH2upGtz/P5mhtE7Ma+TRu7EjIjnM0SZIelw2zM0cnnyv6ZSIIuIWCdpXa7fX1VE3CvJuXNMRT/cGj9Njhlttzj+7kxZJBWx8D26oD030++XXrlYvUTSg5JWRkTPLr+MiKdsf1/SPyW9JOl3EVH5APxRLCYC00zuhe+CFrSzL1bbXqCRV1cnSDpa0hzbk56KpFED3StmcbyQhe9SFrRLWKw+U9LfI2JHROyXdKuk9062CI0a6F4Ri+OlLHyXsqBdyGL1PyWdavuI5t/PGZrCgma2OWpguoiIYduji+MNSddnWhwfXfj+s+2Nze99o7keNKiy3okZEett3yxpg0Z25TykKbyVnGNOAaBwTH0AQOFo1ABQOBo1ABSORg0AhaNRA0DhaNQAUDgaNQAU7n8Usgv/8hRdjwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kbZY0qx_S6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}